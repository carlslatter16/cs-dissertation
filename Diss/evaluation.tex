\chapter {Discussion of Meaningful Defence}
\section {Social Engineering Resilience}
%task2
We cannot patch out human psychology. It is the very thing that distinguishes us from the machine. That would have a disastrous impact on social interaction, innovation and creativity. Baring the idea of a cyborg nation, what can the company do exactly? 
Employee training can go a long way. Provided training can increase alertness to malicious social encounters. The idea with security is not to eliminate, but to simply mitigate with obstacles. These additional hurdles create hardship that make the golden egg seem less worthwhile [2].
Training relevant to social engineering resilience would include physical or voice call validation of requests, thorough checking of email headers and the ability to question authority to at least a basic extent. The fact employees meet once a week could be used as a verification for important requests.
The more alert employees are, the more these kinds of people will be stopped on attempt. An excellent test for this is the physical penetration test. Essentially the idea is to mimic the attacker minus the intent. The company get results, without damage. These results can go a long way in accessing the overall attack surface and the rational of employees [3]. Studies indicate that a penetration test can have yield great progress; care should be taken to adjust company focus and mindset to have security in mind. A penetration test is only as good as how receptive the company is to change, and to hire for security proactively going forward [4].

%task2
\section {Adequatte Use Of Cryptography}
Plain text data is not secure; hence we need encryption. There are some ways to improve how we handle sensitive data, namely using encryption on data in transit, data at rest and also with how we authenticate. The company should instead store a hash representation of that password on the server and compare that with the hash the user generates on login attempt. This means the password is stored on no internal system [11].
This would be vulnerable to a rainbow table attack in which pre-computed hashes are compared to their plain text counterpart. The password test123 would have the always have the same hash which means that passwords can cracked instantly by cross-referencing. The solution to this is another key called a salt that the server holds (separately). This key transforms the hash into another value that cannot be deciphered without it and adds another layer of security [12]. This means an attacker would need the stolen hash, and the randomized salt key. If hash and salt are separated, then this is quite the challenge.
Encryption of emails can be leveraged to improve security alongside hashes that verify people, attachments and messages [9].
Regarding passwords, we need credentials that are difficult to guess. There are two approaches depending on preference. The company can introduce password managers with credentials of length and complexity [12]. Another solution also being what NCSC suggests; three random words into a single password. This is both long enough to make brute force difficult enough and also fairly easy to recall for the end user [13].

\section {Denial Of Service Mitigation}
Denial of service is rather hard to combat, someone with enough hardware to make the attack distributed can take infrastructure down eventually. What we can do is to both make this more difficult, making the situation beyond the simple task of running an automated tool [15]. 
The first mitigation strategy is to block ICMP / ping traffic. The attack works in large part because the server must reply to the ping, which raises process utilization and pulls away everything else on the server. If we can block this then it can go a long way to improve resilience [15].
This is not a complete solution unfortunately. By either creating a windows firewall rule or Linux kernel flag, there is something added that needs to be processed. The load of that processing is not as heavy as a reply but is still present and as a result, the system can be taken down given an increased amount of effort and hardware power [15].
A team of me and 3 others conducted an experiment in which we tested to see if the ICMP blocking greatly reduced the impact of DOS. We sent 1 million ping requests from both a single computer and then two computers to see if there was a notable difference when you block requests. You can see from the below results that it does help greatly. The idea being that despite us using low powered hardware; a realistic attack would also be greater in power indicating that it is scalable.

%mygraph

Another common mitigation technique is load balancing. Commonly there would be different IP addresses and domain names for the hosts and services on the network, with each corresponding to a specific machine. We can assign domain names and create a pool of IP addresses for that name. This will mean that when the domain is accessed, it will be resolved in the DNS server as ONE of those IP addresses, in a round robin approach. This shares load and makes it so an attacker must take down all of the hosts at the same time to take down a system fully [15].
The same philosophy of redundancy must be shared to all aspects of the network, including the DNS architecture because if there is only a single server responsible for everything and that gets taken down then what does the company do? It is incredibly important to have version control of data, with multiple copies. Most common solutions include a local backup, a tape backup off site and then a secure cloud solution. A solution should encompass the CIA triad discussed earlier [16].

%need more - this is where I get lots of words!

\chapter{Evaluation Of Project}
The project has notably changed in scope and direction. The plan initially was to analyse malware and compare them to their respective defence technologies but that grew to be too large in scope when focus was put onto the attack I deemed most interesting. I preferred to go deeper into DNS exfiltration after the research process.
The malware environment does operate as a good virtual machine hub and as such was suitible for hobbyist malware testing and tool development alike. The discussion of defence technologies stands as the focus of the project is still on the bigger picture, with a case study given to the scope of the project to illustate such issues that are present.
This project was also conducted under COVID-19 restrcitions which has slowed progress on all stages of research. The project has changed in direction, structure and also what is provided at the end (for the better). The project has been useful for identifyubg various kinds of mechanisms that malware can employ, and the arms race to defence as a result. 

\chapter{Future Recommendations}
This project is a good illustration of the arms race - one side innvoates, the other side is then forced to as well, lest they be weakened. There was a fair amount of programming inside this project considering it is investgative, and as such there is much in terms of varaiability.
In aspiring to heights of accuracy and user defined detection strength, I discovered that there is a project in itself of finding the most optimum settings for large and varied datasets. This would be conducted using statistical analysis methodologies and possibly machine learning driven simulation.
There will be clear limits of such a program, but it would be useful to find them and optimize the process. This project was an overall view with DNSExfiltration being a portrayed as an example, the next could be with the view on the technologies to push it further. This furter illustrates the point of discussion surrounding
AI and automated threat intelligence, an area that I can see the application of, that is the natural progression. The fact this revelation was found naturally and also in research shows the project went the right direction in the end, with generic malware analysis discussed also to be able to discover present mechanisms.

\chapter{Conclusion}
There are issues indentified throughout this paper - notably the fact that some attacks are not seen as worth filtering because they are not overt in nature. Ransomware (for example) would be prioritised over \'Exfil-Ware\' to the point where it could be forgotten entirely. This is present in the fact that notable and free IDPS systems were tested as part of the project and did
not pass the testing for my kind of attack. While it is important to understand that my attack has it's own fingerprint, it still follows the standard characteristcs of the well known and used DNS exfiltration method. This is employed by both malware and pentesters so it is important that DNS is monitored. Thankfully such platforms are modular and would allow for such features to be added by anybody.
This may not always be the case with some enterprise and paid solutions in which there is less control over what can be added. Snort is open source, a great beneift to security professionals who wish to caiter it to their need. THis paper represents the need to have defencce in depth, to treat security as a layered apprach and to repect it for the challenges it poses.
Such challenges must be fought in order to protect the integrity of technology, with time and potentially capital being put into securing infrastructure and the workforce. This solutions do not nessesarily need to be monitary, but they must be representative of the threats out there today.

%make this terse - flowery atm!
%rerefrence the defence stuff - including use of my own assingmnt